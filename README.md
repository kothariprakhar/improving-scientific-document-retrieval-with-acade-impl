# Improving Scientific Document Retrieval with Academic Concept Index

Adapting general-domain retrievers to scientific domains is challenging due to the scarcity of large-scale domain-specific relevance annotations and the substantial mismatch in vocabulary and information needs. Recent approaches address these issues through two independent directions that leverage large language models (LLMs): (1) generating synthetic queries for fine-tuning, and (2) generating auxiliary contexts to support relevance matching. However, both directions overlook the diverse academic concepts embedded within scientific documents, often producing redundant or conceptually narrow queries and contexts. To address this limitation, we introduce an academic concept index, which extracts key concepts from papers and organizes them guided by an academic taxonomy. This structured index serves as a foundation for improving both directions. First, we enhance the synthetic query generation with concept coverage-based generation (CCQGen), which adaptively conditions LLMs on uncovered concepts to generate complementary queries with broader concept coverage. Second, we strengthen the context augmentation with concept-focused auxiliary contexts (CCExpand), which leverages a set of document snippets that serve as concise responses to the concept-aware CCQGen queries. Extensive experiments show that incorporating the academic concept index into both query generation and context augmentation leads to higher-quality queries, better conceptual alignment, and improved retrieval performance.

## Implementation Details

## Explanation of the Implementation

This implementation captures the core contributions of the paper "Improving Scientific Document Retrieval with Academic Concept Index": **CCQGen** (Concept Coverage-based Query Generation) and **CCExpand** (Concept-focused Auxiliary Contexts).

### 1. Academic Concept Indexing
In the paper, an Academic Concept Index is built by extracting entities from documents and organizing them using a taxonomy (like the Open Academic Graph). 

*   **Code Mapping**: The `ConceptExtractor` class simulates this. In a production environment, this would involve Named Entity Recognition (NER) specialized for science or LLM-based extraction.

### 2. CCQGen: Concept Coverage-based Query Generation
Standard approaches typically prompt an LLM with just the document ($d$) to generate a query ($q$), i.e., $P(q|d)$. This often leads to queries focused only on the abstract or the dominant topic, missing fine-grained details.

CCQGen changes the probability model to $P(q|d, c)$, where $c$ is a specific academic concept found in the document. This forces the LLM to generate questions about specific, sometimes obscure, technical details.

*   **Code Mapping**: The `CCQGen` class iterates through the list of extracted concepts. For each concept, it calls `llm.generate_query(doc, concept)`. 
*   **Result**: This creates a diverse set of synthetic training pairs $(q_{syn}, d)$ that cover the full semantic breadth of the document, preventing the "concept forgetting" problem.

### 3. CCExpand: Concept-focused Auxiliary Contexts
Scientific documents are often dense and long. Standard retrieval models might fail to match a specific query if the relevant text is buried or phrased complexly. CCExpand augments the document with concise "answers" to the queries generated by CCQGen.

*   **Logic**: $D_{expanded} = D_{original} \oplus \text{Context}(d, q_{c1}) \oplus \text{Context}(d, q_{c2}) ...$
*   **Code Mapping**: The `CCExpand` class takes the queries generated in the previous step and asks the LLM to generate a "snippet response" or context. It then concatenates these responses to the original document text using a separator (`[SEP]`).
*   **Benefit**: This enriches the document embedding with variations of phrasing and direct answers to potential user queries, reducing the vocabulary mismatch between search queries and scientific text.

### 4. Dense Retrieval Training
The system uses the data generated above to train a Dense Retriever (Bi-Encoder). 

*   **Architecture**: We use a BERT-based architecture (`sentence-transformers/all-MiniLM-L6-v2`) via the `DenseRetriever` class.
*   **Training Objective**: We use **Contrastive Loss** (InfoNCE). The model learns to maximize the dot product between the synthetic query $q$ and its corresponding expanded document $d^+$, while minimizing the score with other documents in the batch (in-batch negatives).
*   **Workflow**: 
    1.  Concepts are extracted.
    2.  Queries are generated (CCQGen).
    3.  Documents are expanded (CCExpand).
    4.  The Retriever is trained on $(q_{syn}, d_{expanded})$ pairs.

### Summary of Improvements
By explicitly modeling **concepts**, the system ensures that the dense retriever is trained on data that covers the entire document (CCQGen) and that the document representation itself is semantically enriched to answer those specific conceptual queries (CCExpand).